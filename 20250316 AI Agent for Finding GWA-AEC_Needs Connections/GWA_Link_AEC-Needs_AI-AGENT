# THIS IS THE TINKER CODE FILE
import warnings
warnings.filterwarnings("ignore", category=Warning)  # Add this to handle SSL warnings

# Configuration flags
USE_OPENAI = True        # Set to False to use dummy responses instead of OpenAI
SKIP_CATEGORIZATION = False  # Set to True to skip categorizing leads
SKIP_STAKEHOLDER_MAP = False  # Set to True to skip creating stakeholder map - THIS DOESN'T SHOW MUCH WHEN THERE ARE 10+ COMPANIES BUT IS NEEDED TO FIND COMPANY CONNETIONS
SKIP_PROPOSITIONS = False  # Set to True to skip generating propositions
SKIP_RELATIONS_CSV = True  # Set to True to skip creating company relations CSV - NOT CURRENTLY MEANINGFUL
USE_DEFAULT_URL = True  # Set to True to use default URL, False to prompt for URL
DEFAULT_URL = "https://www.presien.com/"  # Default company URL to analyze

# Define constants
NUM_COMPANIES = 25  # Number of companies to search for
NUM_RELATED_COMPANIES = 25  # Number of related companies to find

import os
from typing import List, Dict, Any, Tuple
from langgraph.graph import Graph
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, SystemMessage
from langchain_community.utilities.google_search import GoogleSearchAPIWrapper
import networkx as nx
import matplotlib.pyplot as plt
import pandas as pd
import sys
from dotenv import load_dotenv, set_key
from pathlib import Path
from tqdm import tqdm
import time  # Add this import at the top
from concurrent.futures import ThreadPoolExecutor, as_completed
from fpdf import FPDF  # Change back to standard FPDF
import json
import tkinter as tk
from tkinter import messagebox

def get_dummy_response(prompt: str) -> str:
    """Generate dummy responses when OpenAI is disabled"""
    if "categorize" in prompt.lower():
        return "ConTech Startup"
    elif "connection" in prompt.lower() or "synergy" in prompt.lower():
        return "Yes"
    else:
        return "Sample proposition: Let's collaborate on a pilot project to implement your technology."

def setup_api_keys():
    """Setup API keys with user input if not found in environment"""
    # Load existing .env file or create if doesn't exist
    env_path = Path(get_script_dir()) / '.env'
    env_path.touch(exist_ok=True)
    load_dotenv(env_path)
    
    # Check for OpenAI API key
    if USE_OPENAI and not os.getenv('OPENAI_API_KEY'):
        print("\n‚ö†Ô∏è OPENAI_API_KEY not found in environment variables")
        api_key = input("Please enter your OpenAI API key: ").strip()
        set_key(env_path, 'OPENAI_API_KEY', api_key)
        os.environ['OPENAI_API_KEY'] = api_key
        print("‚úÖ OpenAI API key saved")

# Initialize API clients after setting up keys
def initialize_clients():
    clients = {}
    
    if USE_OPENAI:
        clients["llm"] = ChatOpenAI(model="gpt-4o-mini")
    else:
        print("‚ÑπÔ∏è Using dummy responses instead of OpenAI")
        clients["llm"] = type('DummyLLM', (), {
            'invoke': lambda self, messages: type('DummyResponse', (), {'content': get_dummy_response(messages[-1].content)})()
        })()
    
    return clients

def get_script_dir():
    """Get the directory where the script is located"""
    return os.path.dirname(os.path.abspath(__file__))

def get_company_input():
    """Get company URL from user or use default"""
    print("\nüîç Company Input:")
    print("==================================================")
    
    if USE_DEFAULT_URL:
        print(f"Using default URL: {DEFAULT_URL}")
        return DEFAULT_URL
    
    while True:
        company_url = input("Please enter the company's website URL: ").strip()
        if company_url:  # Check if URL is not empty
            return company_url
        print("URL cannot be empty. Please try again.")

def clean_text(text: str) -> str:
    """Clean text from OpenAI responses"""
    if not isinstance(text, str):
        return str(text)
    
    # Replace smart quotes and apostrophes with standard ASCII versions
    replacements = {
        ''': "'",  # Smart single quote (right)
        ''': "'",  # Smart single quote (left)
        '"': '"',  # Smart double quote (right)
        '"': '"',  # Smart double quote (left)
        '‚Ä¶': '...',  # Ellipsis
        '‚Äì': '-',  # En dash
        '‚Äî': '-',  # Em dash
        '‚Ä¢': '*',  # Bullet point
        '\u2019': "'",  # Unicode right single quotation mark
        '\u2018': "'",  # Unicode left single quotation mark
        '\u201C': '"',  # Unicode left double quotation mark
        '\u201D': '"',  # Unicode right double quotation mark
    }
    
    for old, new in replacements.items():
        text = text.replace(old, new)
    
    return text

class AECNetworkAgent:
    def __init__(self, clients):
        self.categories = {
            "ConTech Startup": [],
            "ConTech Investors": [],
            "ConTech Adopter": [],
        }
        self.connections = []
        self.llm = clients["llm"]
        self.output_dir = get_script_dir()
        
        # Add references as a class variable
        self.references = [
            "https://www.crunchbase.com/",
            "https://contechroundup.substack.com/",
            "https://builtworlds.com/",
            "https://builtworlds.com/insights/2024-builtworlds-top-50-venture-investors/",
            "https://builtworlds.com/insights/2024-top-50-venture-investments-deals/",
            "https://builtworlds.com/insights/2025-building-tech-top-50-list/",
            "https://builtworlds.com/insights/2024-adoption-leaders-50-list/",
            "https://builtworlds.com/insights/2024-global-innovators-list-new/",
            "https://builtworlds.com/insights/2025-preconstruction-tech-top-50-list/",
            "https://www.constructiondive.com/",
            "https://www.constructiondive.com/news/contech-startups-to-watch-2024/632886/",
            "https://brickmortar.vc/portfolio",
            "https://techcrunch.com/"
        ]

    def analyze_main_company(self, company_url: str) -> Dict:
        """Analyze the main company from URL"""
        print("\nüîç Analyzing main company...")
        
        try:
            company_prompt = f"""
            Analyze the company at this URL: {company_url}
            
            Provide the following information in this exact format:
            Company: [company name]
            Description: [Start with a brief description of what they do, then specify their main technology stack (e.g., Computer Vision, IoT Sensors, Cloud Platform, AI/ML, etc.). Be specific about the core technologies they use. The description should be concise and to the point, and should not be more than 300 words. THe description should detail the benefits they bring to the AEC secotr & how their product is used in the sector.]
            Category: [exactly one of: ConTech Startup, ConTech Investors, or ConTech Adopter]
            
            Example description format:
            Description: A safety monitoring solution provider that uses AI-powered Computer Vision technology combined with IoT sensors to detect workplace hazards. Their tech stack includes: Computer Vision, Deep Learning Models, Edge Computing devices, and Real-time Alert System.
            
            Be specific and detailed in the description, always including the technology components.
            """
            
            response = self.llm.invoke([
                SystemMessage(content="You are a construction technology industry expert."),
                HumanMessage(content=company_prompt)
            ])
            
            # Clean the response text immediately
            cleaned_response = clean_text(response.content)
            
            # Parse the response
            lines = cleaned_response.strip().split('\n')
            main_company = {}
            for line in lines:
                if ':' in line:
                    key, value = line.split(':', 1)
                    main_company[key.strip()] = value.strip()
            
            return main_company
            
        except Exception as e:
            print(f"\n‚ùå Error analyzing company: {str(e)}")
            return None

    def search_and_collect_data(self, main_company: Dict, company_url: str) -> Dict[str, List[Dict]]:
        print("\nüîç Finding related companies...")
        
        try:
            # Calculate number of companies for each category
            num_startups = round(NUM_RELATED_COMPANIES * 0.3)  # 30% startups
            num_investors = round(NUM_RELATED_COMPANIES * 0.2)  # 20% investors
            num_adopters = NUM_RELATED_COMPANIES - num_startups - num_investors  # Remaining for adopters (‚âà50%)
            
            # Create references string from the array
            references_text = "\n".join(f"- {ref}" for ref in self.references)
            
            openai_prompt = f"""
            Find EXACTLY {NUM_RELATED_COMPANIES} real companies that could be relevant to:
            Company: {main_company['Company']}
            Category: {main_company['Category']}
            Description: {main_company['Description']}

            You MUST provide EXACTLY:
            - {num_startups} companies from category 1 (startups/innovators)
            - {num_investors} companies from category 2 (investors)
            - {num_adopters} companies from category 3 (adopters)

            Categories explained:
            1) startups, innovators, creators, technology suppliers, early stage companies
            2) corporate venture capital, private equity, venture capitalists, investors
            3) adopters (established companies using or potentially using such technologies)

            Focus on finding:
            1. Direct competitors with similar technology stacks
            2. Potential partners with complementary technologies
            3. Companies in their value chain (suppliers/customers)
            4. Companies with complementary technologies

            REFERENCES Use the following urls to complete this search task:
            {references_text}

            For each company, include:
            Company: [name]
            Description: [Start with a brief description of what they do, then specify their main technology stack (e.g., Computer Vision, IoT Sensors, Cloud Platform, AI/ML, etc.). Be specific about the core technologies they use. The description should be concise and to the point, and should not be more than 300 words. THe description should detail the benefits they bring to the AEC secotr & how their product is used in the sector.]
            Category: [exactly one of: ConTech Startup, ConTech Investors, or ConTech Adopter]
            URL: [company website URL - this is required, do not skip]
            
            Note: Always provide a valid website URL for each company. If you can't find the exact URL, provide the company's main domain.
            
            Format each entry exactly as shown above, with each field on a new line.
            Separate companies with a blank line.
            """
            
            print(f"Finding exactly {NUM_RELATED_COMPANIES} related companies ({num_startups} startups, {num_investors} investors, {num_adopters} adopters)...")
            
            response = self.llm.invoke([
                SystemMessage(content="You are a construction technology industry expert."),
                HumanMessage(content=openai_prompt)
            ])
            
            results = {"openai": []}
            company_data = self._parse_openai_response(response.content)
            if company_data:
                results["openai"].extend(company_data)
                
            # Add main company to results
            main_company_data = {
                "name": main_company["Company"],
                "description": main_company["Description"],
                "category": main_company["Category"],
                "url": company_url,
                "is_main": True  # Flag to identify the main company
            }
            results["openai"].insert(0, main_company_data)
            
            # Move the PDF generation to after all analysis is complete
            return results
        
        except Exception as e:
            print(f"\n‚ùå Error finding related companies: {str(e)}")
            return {"openai": []}

    def _parse_openai_response(self, content: str) -> List[Dict]:
        """Helper method to parse OpenAI response into structured data"""
        # Clean the content immediately
        content = clean_text(content)
        
        companies = []
        current_company = {}
        
        lines = content.strip().split('\n')
        for line in lines:
            line = line.strip()
            if not line:
                if current_company and "name" in current_company:
                    companies.append(current_company)
                    current_company = {"is_main": False}
                continue
            
            if line.lower().startswith("company:"):
                if current_company and "name" in current_company:
                    companies.append(current_company)
                    current_company = {"is_main": False}
            
            if ":" in line:
                parts = line.split(":", 1)
                key = parts[0].strip().lower()
                value = clean_text(parts[1].strip())
                
                if "company" in key:
                    current_company["name"] = value
                elif "description" in key:
                    current_company["description"] = value
                elif "category" in key:
                    current_company["category"] = value
                elif "url" in key or "website" in key:
                    current_company["url"] = value.strip()
                    if current_company["url"].lower() == "n/a":
                        current_company["url"] = ""
        
        # Add the last company if exists
        if current_company and "name" in current_company:
            companies.append(current_company)
        
        # Validate and enforce the exact number of companies
        if len(companies) > NUM_RELATED_COMPANIES:
            companies = companies[:NUM_RELATED_COMPANIES]
        elif len(companies) < NUM_RELATED_COMPANIES:
            # Fill with placeholder companies if we don't have enough
            while len(companies) < NUM_RELATED_COMPANIES:
                category = "ConTech Startup"
                if len([c for c in companies if c.get("category") == "ConTech Investors"]) < 1:
                    category = "ConTech Investors"
                elif len([c for c in companies if c.get("category") == "ConTech Adopter"]) < 1:
                    category = "ConTech Adopter"
                
                companies.append({
                    "name": f"Additional Company {len(companies) + 1}",
                    "description": "Additional company details not available",
                    "category": category,
                    "url": "N/A",
                    "is_main": False
                })
        
        # Validate category distribution
        category_counts = {
            "ConTech Startup": 0,
            "ConTech Investors": 0,
            "ConTech Adopter": 0
        }
        
        for company in companies:
            cat = company.get("category", "ConTech Startup")
            category_counts[cat] = category_counts.get(cat, 0) + 1
        
        # Adjust categories if needed
        target_counts = {"ConTech Startup": 3, "ConTech Investors": 1, "ConTech Adopter": 1}
        for i, company in enumerate(companies):
            current_cat = company.get("category", "ConTech Startup")
            for target_cat, target_count in target_counts.items():
                if category_counts[current_cat] > target_counts[current_cat] and category_counts[target_cat] < target_count:
                    companies[i]["category"] = target_cat
                    category_counts[current_cat] -= 1
                    category_counts[target_cat] += 1
        
        # Ensure all required fields exist with proper defaults
        for company in companies:
            company.setdefault("name", "Unknown")
            company.setdefault("description", "N/A")
            company.setdefault("category", "ConTech Startup")
            company.setdefault("url", "")  # Default to empty string instead of N/A
        
        # Clean up URL if it exists
        if company["url"]:
            company["url"] = company["url"].strip()
            # Ensure URL has http:// or https:// prefix
            if not company["url"].startswith(("http://", "https://")):
                company["url"] = "https://" + company["url"]
        
        return companies

    def categorize_leads(self, data: Dict[str, List[Dict]]) -> pd.DataFrame:
        categorized_data = []
        BATCH_SIZE = 5  # Process 5 companies at a time
        
        # Flatten the data into a single list
        all_companies = []
        for source, results in data.items():
            for result in results:
                if isinstance(result, str):
                    result = {"name": result, "description": result, "url": "N/A"}
                result["source"] = source
                all_companies.append(result)
        
        total_batches = (len(all_companies) + BATCH_SIZE - 1) // BATCH_SIZE
        
        with tqdm(total=len(all_companies), desc="Categorizing companies") as pbar:
            for i in range(0, len(all_companies), BATCH_SIZE):
                batch = all_companies[i:i + BATCH_SIZE]
                
                # Create batch prompt
                batch_prompt = "Categorize each company into exactly one category: ConTech Startup, ConTech Investors, or ConTech Adopter.\n\n"
                for idx, company in enumerate(batch, 1):
                    clean_name = company.get('name', 'Unknown').replace('*', '').strip()
                    batch_prompt += f"Company {idx}:\nName: {clean_name}\nDescription: {company.get('description', 'N/A')}\n\n"
                
                batch_prompt += "Return ONLY a comma-separated list of categories in order, e.g.: 'ConTech Startup, ConTech Investors, ConTech Adopter'"
                    
                response = self.llm.invoke([
                    SystemMessage(content="You are a construction technology expert. Respond only with comma-separated categories."),
                    HumanMessage(content=batch_prompt)
                ])
                
                # Parse categories
                categories = [cat.strip() for cat in response.content.split(',')]
                
                # Add categorized companies to results
                for company, category in zip(batch, categories):
                    clean_name = company.get('name', 'Unknown').replace('*', '').strip()
                    categorized_data.append({
                        "name": clean_name,
                        "category": category,
                        "description": company.get("description", ""),
                        "url": company.get("url", "N/A"),
                        "source": company.get("source", "unknown"),
                        "is_main": company.get("is_main", False)
                    })
                    pbar.update(1)
        
        # Create DataFrame
        df = pd.DataFrame(categorized_data)
        
        # Rename columns to match the expected format
        df = df.rename(columns={
            "name": "Name",
            "category": "Category",
            "description": "Description",
            "url": "URL",
            "source": "Source"
        })
        
        return df[["Name", "Category", "Description", "URL", "Source", "is_main"]]

    def create_stakeholder_map(self, df: pd.DataFrame) -> nx.Graph:
        G = nx.Graph()
        
        # Add nodes
        main_company = df[df['is_main'] == True].iloc[0]
        other_companies = df[df['is_main'] == False]
        
        # Add main company node first
        G.add_node(main_company["Name"], 
                   category=main_company["Category"],
                   is_main=True)
        
        # Add other company nodes
        for _, row in other_companies.iterrows():
            G.add_node(row["Name"], 
                      category=row["Category"],
                      is_main=False)
        
        # Analyze connections with main company first
        print("\nüîç Analyzing connections with main company...")
        with tqdm(total=len(other_companies), desc="Main company connections") as pbar:
            for _, other_company in other_companies.iterrows():
                connection_prompt = f"""
                Analyze if there's a potential connection between these companies:
                
                Company 1 (Main): {main_company['Name']} ({main_company['Category']})
                Description: {main_company['Description']}
                
                Company 2: {other_company['Name']} ({other_company['Category']})
                Description: {other_company['Description']}
                
                Consider these types of connections:
                1. Direct competition (same market/solutions)
                2. Potential partnership opportunities
                3. Value chain relationship (supplier/customer)
                4. Technology complementarity
                5. Similar target market
                
                Respond with EXACTLY one line containing only 'Yes' or 'No'.
                """
                
                try:
                    response = self.llm.invoke([
                        SystemMessage(content="You are analyzing business connections. Respond only with Yes or No."),
                        HumanMessage(content=connection_prompt)
                    ])
                    
                    # Clean up response and check for connection
                    response_text = response.content.strip().lower()
                    if 'yes' in response_text:
                        G.add_edge(main_company["Name"], other_company["Name"])
                        print(f"\n‚úÖ Connection found: {main_company['Name']} - {other_company['Name']}")
                except Exception as e:
                    print(f"\n‚ùå Error analyzing connection: {str(e)}")
                
                pbar.update(1)
        
        # Analyze connections between other companies (optional, can be skipped for larger datasets)
        if len(other_companies) < 20:  # Only do this for smaller datasets
            print("\nüîç Analyzing connections between other companies...")
            total_pairs = (len(other_companies) * (len(other_companies) - 1)) // 2
            with tqdm(total=total_pairs, desc="Other connections") as pbar:
                for i, company1 in other_companies.iterrows():
                    for j, company2 in other_companies.iterrows():
                        if i < j:  # Avoid checking same pair twice
                            connection_prompt = f"""
                            Analyze if there's a potential connection between these companies:
                            
                            Company 1: {company1['Name']} ({company1['Category']})
                            Description: {company1['Description']}
                            
                            Company 2: {company2['Name']} ({company2['Category']})
                            Description: {company2['Description']}
                            
                            Consider these types of connections:
                            1. Direct competition (same market/solutions)
                            2. Potential partnership opportunities
                            3. Value chain relationship (supplier/customer)
                            4. Technology complementarity
                            5. Similar target market
                            
                            Respond with EXACTLY one line containing only 'Yes' or 'No'.
                            """
                            
                            try:
                                response = self.llm.invoke([
                                SystemMessage(content="You are analyzing business connections. Respond only with Yes or No."),
                                HumanMessage(content=connection_prompt)
                        ])
                        
                                # Clean up response and check for connection
                                response_text = response.content.strip().lower()
                                if 'yes' in response_text:
                                    G.add_edge(company1["Name"], company2["Name"])
                                    print(f"\n‚úÖ Connection found: {company1['Name']} - {company2['Name']}")
                            except Exception as e:
                                print(f"\n‚ùå Error analyzing connection: {str(e)}")
                        
                        pbar.update(1)
        
        return G

    def generate_propositions(self, main_company: Dict, related_companies: List[Dict], G: nx.Graph) -> Dict:
        """Generate propositions for each connected company"""
        propositions = {}
        print("\nü§î Analyzing potential collaborations...")
        
        # Get direct connections to main company
        main_connections = [n for n in G.neighbors(main_company['Company'])]
        
        for company_name in tqdm(main_connections, desc="Generating propositions"):
            try:
                # Find the connected company details
                connected_company = next(
                    (c for c in related_companies if 
                     c.get('name', '') == company_name or 
                     c.get('Company', '') == company_name),
                    None
                )
                
                if connected_company:
                    prompt = f"""
                    Analyze the potential collaboration between these two companies:
                    
                    Company 1: {main_company['Company']}
                    Description: {main_company['Description']}
                    Category: {main_company['Category']}
                    
                    Company 2: {company_name}
                    Description: {connected_company.get('description', connected_company.get('Description', 'N/A'))}
                    Category: {connected_company.get('category', connected_company.get('Category', 'N/A'))}
                    
                    Please provide in this exact format:
                    Connection Type: [type of potential connection, e.g., partnership, client-supplier, investor-startup]
                    Synergy Details: [detailed explanation of how the companies complement each other]
                    Value Proposition: [clear value proposition for both companies]
                        """
                        
                    response = self.llm.invoke([
                    SystemMessage(content="You are analyzing business collaborations. Provide your analysis in the requested format."),
                    HumanMessage(content=prompt)
                    ])
                    
                    # Clean the response text immediately
                    cleaned_response = clean_text(response.content)
                    
                    # Parse the response into sections
                    sections = {}
                    current_section = None
                    current_text = []
                    
                    for line in cleaned_response.split('\n'):
                        line = line.strip()
                        if not line:
                            continue
                        
                        if line.startswith('Connection Type:'):
                            current_section = 'connection_type'
                            current_text = [line.split(':', 1)[1].strip()]
                        elif line.startswith('Synergy Details:'):
                            if current_section and current_text:
                                sections[current_section] = ' '.join(current_text)
                            current_section = 'synergy_details'
                            current_text = [line.split(':', 1)[1].strip()]
                        elif line.startswith('Value Proposition:'):
                            if current_section and current_text:
                                sections[current_section] = ' '.join(current_text)
                            current_section = 'value_proposition'
                            current_text = [line.split(':', 1)[1].strip()]
                        else:
                            current_text.append(line)
                    
                    # Add the last section
                    if current_section and current_text:
                        sections[current_section] = ' '.join(current_text)
                    
                    propositions[company_name] = {
                        'connection_type': sections.get('connection_type', 'Not specified'),
                        'synergy_details': sections.get('synergy_details', 'Not specified'),
                        'value_proposition': sections.get('value_proposition', 'Not specified')
                    }
                    
            except Exception as e:
                print(f"\n‚ùå Error analyzing {company_name}: {str(e)}")
                continue
        
        return propositions

    def visualize_stakeholder_map(self, G: nx.Graph):
        plt.figure(figsize=(15, 10))  # Increased figure size
        
        # Use a more spread out layout
        pos = nx.spring_layout(G, k=1, iterations=50)  # k=1 increases spacing between nodes
        
        # Draw nodes for each category with different colors
        colors = {
            "ConTech Startup": "skyblue",
            "ConTech Investors": "lightgreen",
            "ConTech Adopter": "salmon",
        }
        
        # Draw regular nodes first
        for category, color in colors.items():
            nodes = [node for node, attr in G.nodes(data=True) 
                    if attr.get("category") == category and not attr.get("is_main", False)]
            nx.draw_networkx_nodes(G, pos, nodelist=nodes, node_color=color, 
                                 node_size=1000, alpha=0.7)
        
        # Draw main company node with special formatting
        main_nodes = [node for node, attr in G.nodes(data=True) if attr.get("is_main", True)]
        if main_nodes:
            nx.draw_networkx_nodes(G, pos, nodelist=main_nodes, 
                                 node_color='gold',  # Different color for main company
                                 node_size=2000,     # Larger size
                                 alpha=1.0,          # Full opacity
                                 edgecolors='red',   # Red border
                                 linewidths=2)       # Thicker border
        
        # Draw edges with better visibility
        nx.draw_networkx_edges(G, pos, 
                              edge_color='gray',
                              width=2,
                              alpha=0.6,
                              style='solid')
        
        # Add labels with better formatting
        labels = nx.get_node_attributes(G, 'name')
        nx.draw_networkx_labels(G, pos, 
                              font_size=8,
                              font_weight='bold')
        
        # Add legend with main company
        legend_elements = [
            plt.Line2D([0], [0], marker='o', color='w', 
                         markerfacecolor=color, label=cat, markersize=10)
            for cat, color in colors.items()
        ]
        legend_elements.append(
            plt.Line2D([0], [0], marker='o', color='w',
                       markerfacecolor='gold', label='Main Company',
                       markersize=12, markeredgecolor='red', markeredgewidth=2)
        )
        plt.legend(handles=legend_elements, loc='upper left', bbox_to_anchor=(1, 1))
        
        plt.title("Stakeholder Network", pad=20)
        plt.axis('off')
        plt.tight_layout()
        
        # Save to script directory
        output_path = os.path.join(self.output_dir, 'stakeholder_map.png')
        plt.savefig(output_path, bbox_inches='tight', dpi=300)  # Higher resolution
        plt.close()

    def _safe_text(self, text):
        """Clean and encode text for PDF"""
        if isinstance(text, str):
            # Remove "**" characters
            text = text.replace('**', '')
            # Replace smart quotes and apostrophes with standard ones
            text = text.replace(''', "'").replace(''', "'").replace('"', '"').replace('"', '"')
            # Replace other problematic characters
            replacements = {
                '?': "'",  # Replace question marks that should be apostrophes
                '‚Ä¶': '...',  # Replace ellipsis
                '‚Äì': '-',  # Replace en dash
                '‚Äî': '-',  # Replace em dash
                '‚Ä¢': '*',  # Replace bullet points
            }
            for old, new in replacements.items():
                text = text.replace(old, new)
            return text.encode('latin-1', 'replace').decode('latin-1')
        return str(text)

    def save_initial_search_pdf(self, main_company: Dict, related_companies: List[Dict], G: nx.Graph = None, propositions: Dict = None):
        """Save comprehensive summary report to PDF"""
        # Print summary of companies found
        total_companies = len(related_companies) + 1  # +1 for main company
        print("\nüìÑ Generating summary report...")
        
        from datetime import datetime
        today = datetime.now().strftime("%Y%m%d")
        company_name = "".join(c for c in main_company['Company'] if c.isalnum())
        filename = f"{today}_Network_Analysis_Report_{company_name}.pdf"
        
        # Create PDF
        pdf = FPDF()
        pdf.set_auto_page_break(auto=True, margin=15)
        
        # Helper function to write a labeled field with bold label
        def write_labeled_field(pdf, label, value, multiline=False, large_label=False):
            # Increase font size by 30% for specific labels (12 * 1.3 ‚âà 16)
            if large_label and (label == "Company" or label == "Connection"):
                pdf.set_font("Arial", "B", 16)  # 30% bigger than standard 12
            else:
                pdf.set_font("Arial", "B", 12)
            
            # Write the label and move to next line
            pdf.write(10, f"{label}:")
            pdf.ln(10)  # Add line break after label
            
            # For company names, use larger font size
            if large_label and (label == "Company" or label == "Connection"):
                pdf.set_font("Arial", "", 16)  # Keep content same size as label
            else:
                pdf.set_font("Arial", "", 12)  # Reset to normal size for other content
            
            if multiline:
                pdf.multi_cell(0, 10, self._safe_text(value))
            else:
                pdf.write(10, self._safe_text(value))
                pdf.ln(10)

        try:
            # Generate all sections without progress bar
            # 1. Title Page and Table of Contents
            pdf.add_page()
            pdf.set_font("Arial", "B", 20)
            pdf.cell(0, 20, "Network Analysis", ln=True, align='C')
            pdf.set_font("Arial", "", 12)
            pdf.cell(0, 10, f"Report Date: {datetime.now().strftime('%Y-%m-%d')}", ln=True, align='C')
            pdf.cell(0, 10, f"Analysis for: {self._safe_text(main_company['Company'])}", ln=True, align='C')
            pdf.ln(20)
            
            pdf.set_font("Arial", "B", 16)
            pdf.cell(0, 10, "Table of Contents", ln=True)
            pdf.set_font("Arial", "", 12)
            pdf.cell(0, 10, "1. Main Company Profile", ln=True)
            pdf.cell(0, 10, "2. Network Overview", ln=True)
            pdf.cell(0, 10, "3. Related Companies", ln=True)
            pdf.cell(0, 10, "4. Connections Analysis", ln=True)
            pdf.cell(0, 10, "5. Potential Opportunities", ln=True)
            pdf.cell(0, 10, "6. References", ln=True)
            
            # 2. Main Company Profile
            pdf.add_page()
            pdf.set_font("Arial", "B", 16)
            pdf.cell(0, 10, "1. Main Company Profile", ln=True)
            pdf.ln(5)
            
            write_labeled_field(pdf, "Company", main_company['Company'])
            write_labeled_field(pdf, "Category", main_company['Category'])
            write_labeled_field(pdf, "Description", main_company['Description'], multiline=True)
            pdf.ln(5)
            
            # 3. Network Overview
            pdf.add_page()
            pdf.set_font("Arial", "B", 16)
            pdf.cell(0, 10, "2. Network Overview", ln=True)
            pdf.ln(5)
            
            pdf.set_font("Arial", "", 12)
            total_companies = len(related_companies) + 1
            categories_count = {}
            for company in related_companies:
                cat = company.get('category', 'Uncategorized')
                categories_count[cat] = categories_count.get(cat, 0) + 1
            
            pdf.multi_cell(0, 10, f"Total companies in network: {total_companies}")
            pdf.multi_cell(0, 10, "Distribution by category:")
            for cat, count in categories_count.items():
                pdf.multi_cell(0, 10, self._safe_text(f"- {cat}: {count} companies"))
            
            # 4. Related Companies
            pdf.add_page()
            pdf.set_font("Arial", "B", 16)
            pdf.cell(0, 10, "3. Related Companies", ln=True)
            pdf.ln(5)
            
            companies_by_category = {}
            for company in related_companies:
                cat = company.get('category', 'Uncategorized')
                if cat not in companies_by_category:
                    companies_by_category[cat] = []
                companies_by_category[cat].append(company)
            
            for category, companies in companies_by_category.items():
                pdf.set_font("Arial", "B", 14)
                pdf.cell(0, 10, self._safe_text(category), ln=True)
                pdf.ln(5)
                
                for company in companies:
                    write_labeled_field(pdf, "Company", company['name'], large_label=True)
                    write_labeled_field(pdf, "Description", company.get('description', 'N/A'), multiline=True)
                    url = company.get('url', '')
                    write_labeled_field(pdf, "URL", url if url else 'Not available')
                    pdf.ln(15)
            
            # 5. Connections Analysis
            pdf.add_page()
            pdf.set_font("Arial", "B", 16)
            pdf.cell(0, 10, "4. Connections Analysis", ln=True)
            pdf.ln(5)
            
            if G:
                pdf.set_font("Arial", "", 12)
                main_connections = [n for n in G.neighbors(main_company['Company'])]
                
                # Overview section
                pdf.set_font("Arial", "B", 14)
                pdf.cell(0, 10, "Connection Overview", ln=True)
                pdf.set_font("Arial", "", 12)
                pdf.multi_cell(0, 10, self._safe_text(f"Total direct connections with {main_company['Company']}: {len(main_connections)}"))
                pdf.multi_cell(0, 10, f"Total connections in network: {G.number_of_edges()}")
                pdf.multi_cell(0, 10, f"Network density: {nx.density(G):.2f}")
                pdf.ln(10)
                
                # Add stakeholder map
                pdf.set_font("Arial", "B", 14)
                pdf.cell(0, 10, "Stakeholder Network Map", ln=True)
                pdf.ln(5)
                
                map_path = os.path.join(self.output_dir, 'stakeholder_map.png')
                if os.path.exists(map_path):
                    page_width = pdf.w - 2 * pdf.l_margin
                    img_width = page_width
                    try:
                        from PIL import Image
                        with Image.open(map_path) as img:
                            w, h = img.size
                            img_height = (h * img_width) / w
                            x = pdf.l_margin
                            pdf.image(map_path, x=x, w=img_width)
                    except Exception as e:
                        pdf.multi_cell(0, 10, "Error: Could not include stakeholder map image")
                    pdf.ln(10)
                
                # Detailed connections
                pdf.add_page()
                pdf.set_font("Arial", "B", 14)
                pdf.cell(0, 10, "Direct Connections Details", ln=True)
                pdf.ln(5)
                
                if main_connections:
                    for connection in main_connections:
                        # Find the connected company by matching either name or Company field
                        connected_company = next(
                            (c for c in related_companies if 
                             c.get('name', '') == connection or 
                             c.get('Company', '') == connection),
                            None
                        )
                        
                        if connected_company:
                            write_labeled_field(pdf, "Connection", connected_company['name'], large_label=True)
                            write_labeled_field(pdf, "Category", connected_company.get('category', connected_company.get('Category', 'N/A')))
                            write_labeled_field(pdf, "Description", connected_company.get('description', connected_company.get('Description', 'N/A')), multiline=True)
                            
                            # Check propositions using both possible company name fields
                            prop = None
                            if propositions:
                                prop = propositions.get(connected_company['name']) or propositions.get(connection)
                                
                            if prop:
                                write_labeled_field(pdf, "Connection Type", prop.get('connection_type', 'N/A'), multiline=True)
                                write_labeled_field(pdf, "Synergy", prop.get('synergy_details', 'N/A'), multiline=True)
                            
                            # Use either url or URL field
                            url = connected_company.get('url', connected_company.get('URL', 'N/A'))
                            write_labeled_field(pdf, "URL", url)
                            pdf.ln(15)
                        else:
                            # If we can't find the company details, at least show the connection name
                            write_labeled_field(pdf, "Connection", connection)
                            pdf.set_font("Arial", "I", 12)
                            pdf.multi_cell(0, 10, "(Additional details not available)")
                            pdf.ln(5)
                else:
                    pdf.set_font("Arial", "I", 12)
                    pdf.multi_cell(0, 10, "No direct connections found with the main company.")
            
            # 6. Potential Opportunities
            pdf.add_page()
            pdf.set_font("Arial", "B", 16)
            pdf.cell(0, 10, "5. Potential Opportunities", ln=True)
            pdf.ln(5)
            
            if propositions:
                for company_name, prop_data in propositions.items():
                    pdf.set_font("Arial", "B", 14)
                    pdf.cell(0, 10, self._safe_text(f"Collaboration with {company_name}"), ln=True)
                    
                    write_labeled_field(pdf, "Connection Type", prop_data.get('connection_type', 'N/A'), multiline=True)
                    write_labeled_field(pdf, "Synergy Details", prop_data.get('synergy_details', 'N/A'), multiline=True)
                    write_labeled_field(pdf, "Value Proposition", prop_data.get('value_proposition', 'N/A'), multiline=True)
                    pdf.ln(15)
            else:
                pdf.set_font("Arial", "I", 12)
                pdf.multi_cell(0, 10, "No collaboration propositions were generated.")
            
            # Add References section
            pdf.add_page()
            pdf.set_font("Arial", "B", 16)
            pdf.cell(0, 10, "6. References", ln=True)
            pdf.ln(1)
            
            pdf.set_font("Arial", "", 8)
            pdf.multi_cell(0, 10, "The following sources were consulted for this analysis:")
            pdf.ln(1)
            
            for ref in self.references:
                pdf.multi_cell(0, 10, self._safe_text(f"‚Ä¢ {ref}"))
            
            # Save the PDF
            output_path = os.path.join(self.output_dir, filename)
            pdf.output(output_path)
            print(f"‚úÖ Report generated successfully")
            return output_path
            
        except Exception as e:
            print(f"\n‚ùå Error generating PDF: {str(e)}")
            # Fallback to basic ASCII filename if needed
            fallback_filename = f"{today}_AEC_Summary_Report_Company.pdf"
            output_path = os.path.join(self.output_dir, fallback_filename)
            try:
                pdf.output(output_path)
                return output_path
            except:
                print("‚ùå Could not save PDF even with fallback filename")
                return None

def main():
    # Update configuration status display to include new flag
    print("\nüîß Configuration:")
    print(f"{'‚úÖ' if USE_OPENAI else '‚ùå'} OpenAI API: {'Enabled' if USE_OPENAI else 'Disabled'}")
    print(f"{'‚úÖ' if USE_DEFAULT_URL else '‚ùå'} Default URL: {'Enabled' if USE_DEFAULT_URL else 'Disabled'}")
    print(f"{'‚ûñ' if SKIP_CATEGORIZATION else '‚úÖ'} Categorization: {'Skipped' if SKIP_CATEGORIZATION else 'Enabled'}")
    print(f"{'‚ûñ' if SKIP_STAKEHOLDER_MAP else '‚úÖ'} Stakeholder Map: {'Skipped' if SKIP_STAKEHOLDER_MAP else 'Enabled'}")
    print(f"{'‚ûñ' if SKIP_PROPOSITIONS else '‚úÖ'} Propositions: {'Skipped' if SKIP_PROPOSITIONS else 'Enabled'}")
    print(f"{'‚ûñ' if SKIP_RELATIONS_CSV else '‚úÖ'} Relations CSV: {'Skipped' if SKIP_RELATIONS_CSV else 'Enabled'}")
    print()
    
    # Setup API keys and initialize clients
    setup_api_keys()
    clients = initialize_clients()
    
    # Create agent
    agent = AECNetworkAgent(clients)
    
    # Get company URL from user
    company_url = get_company_input()
    
    # Analyze main company
    main_company = agent.analyze_main_company(company_url)
    if not main_company:
        print("Failed to analyze company. Exiting...")
        return
    
    # Find related companies
    print("üîç Searching for related companies...")
    data = agent.search_and_collect_data(main_company, company_url)
    
    if not SKIP_CATEGORIZATION:
        print("üìä Categorizing companies...")
        categorized_df = agent.categorize_leads(data)
        # Save to script directory
        output_path = os.path.join(agent.output_dir, 'categorized_leads.csv')
        categorized_df.to_csv(output_path, index=False)
    else:
        # Create a basic DataFrame without categorization
        categorized_data = []
        for source, results in data.items():
            for result in results:
                categorized_data.append({
                    "Name": result.get("name", "Unknown"),
                    "Category": result.get("category", "Uncategorized"),
                    "Description": result.get("description", ""),
                    "URL": result.get("url", "N/A"),
                    "Source": source,
                    "is_main": result.get("is_main", False)
                })
        categorized_df = pd.DataFrame(categorized_data)
        output_path = os.path.join(agent.output_dir, 'leads.csv')
        categorized_df.to_csv(output_path, index=False)
    
    if not SKIP_STAKEHOLDER_MAP:
        print("üï∏Ô∏è Creating stakeholder map...")
        G = agent.create_stakeholder_map(categorized_df)
        agent.visualize_stakeholder_map(G)
    
    if not SKIP_PROPOSITIONS:
        print("üìù Generating propositions...")
        propositions = agent.generate_propositions(
            main_company,
            data["openai"],  # This contains the list of related companies
            G if not SKIP_STAKEHOLDER_MAP else None
        )
    else:
        propositions = None
    
    # Generate the comprehensive PDF report at the end
    print("üìÑ Generating summary report...")
    pdf_path = agent.save_initial_search_pdf(
        main_company,
        data["openai"],
        G if not SKIP_STAKEHOLDER_MAP else None,
        propositions
    )
    print(f"üìÑ Summary report saved to: {pdf_path}")
    
    print(f"\n‚úÖ Process complete! Check output files in: {agent.output_dir}")

if __name__ == "__main__":
    main()
