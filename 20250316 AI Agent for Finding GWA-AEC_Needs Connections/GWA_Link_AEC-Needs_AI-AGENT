# THIS IS THE TINKER CODE FILE
import warnings
warnings.filterwarnings("ignore", category=Warning)  # Add this to handle SSL warnings

# Configuration flags
USE_OPENAI = True        # Set to False to use dummy responses instead of OpenAI
SKIP_CATEGORIZATION = False  # Set to True to skip categorizing leads
SKIP_STAKEHOLDER_MAP = False  # Set to True to skip creating stakeholder map - THIS DOESN'T SHOW MUCH WHEN THERE ARE 10+ COMPANIES BUT IS NEEDED TO FIND COMPANY CONNETIONS
SKIP_PROPOSITIONS = False  # Set to True to skip generating propositions
SKIP_RELATIONS_CSV = True  # Set to True to skip creating company relations CSV - NOT CURRENTLY MEANINGFUL

# Define constants
NUM_COMPANIES = 100  # Number of companies to search for
NUM_RELATED_COMPANIES = 25  # Number of related companies to find

import os
from typing import List, Dict, Any
from langgraph.graph import Graph
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, SystemMessage
from langchain_community.utilities.google_search import GoogleSearchAPIWrapper
import networkx as nx
import matplotlib.pyplot as plt
import pandas as pd
import sys
from dotenv import load_dotenv, set_key
from pathlib import Path
from tqdm import tqdm
import time  # Add this import at the top
from concurrent.futures import ThreadPoolExecutor, as_completed
from fpdf import FPDF  # Change back to standard FPDF

def get_dummy_response(prompt: str) -> str:
    """Generate dummy responses when OpenAI is disabled"""
    if "categorize" in prompt.lower():
        return "ConTech Startup"
    elif "connection" in prompt.lower() or "synergy" in prompt.lower():
        return "Yes"
    else:
        return "Sample proposition: Let's collaborate on a pilot project to implement your technology."

def setup_api_keys():
    """Setup API keys with user input if not found in environment"""
    # Load existing .env file or create if doesn't exist
    env_path = Path(get_script_dir()) / '.env'
    env_path.touch(exist_ok=True)
    load_dotenv(env_path)
    
    # Check for OpenAI API key
    if USE_OPENAI and not os.getenv('OPENAI_API_KEY'):
        print("\n⚠️ OPENAI_API_KEY not found in environment variables")
        api_key = input("Please enter your OpenAI API key: ").strip()
        set_key(env_path, 'OPENAI_API_KEY', api_key)
        os.environ['OPENAI_API_KEY'] = api_key
        print("✅ OpenAI API key saved")

# Initialize API clients after setting up keys
def initialize_clients():
    clients = {}
    
    if USE_OPENAI:
        clients["llm"] = ChatOpenAI(model="gpt-4o-mini")
    else:
        print("ℹ️ Using dummy responses instead of OpenAI")
        clients["llm"] = type('DummyLLM', (), {
            'invoke': lambda self, messages: type('DummyResponse', (), {'content': get_dummy_response(messages[-1].content)})()
        })()
    
    return clients

def get_script_dir():
    """Get the directory where the script is located"""
    return os.path.dirname(os.path.abspath(__file__))

def get_company_input():
    """Get company URL from user"""
    print("\n🔍 Company Input:")
    print("==================================================")
    company_url = input("Please enter the company's website URL: ").strip()
    return company_url

class AECNetworkAgent:
    def __init__(self, clients):
        self.categories = {
            "ConTech Startup": [],
            "ConTech Investors": [],
            "ConTech Adopter": [],
        }
        self.connections = []
        self.llm = clients["llm"]
        self.output_dir = get_script_dir()
        
    def analyze_main_company(self, company_url: str) -> Dict:
        """Analyze the main company from URL"""
        print("\n🔍 Analyzing main company...")
        
        try:
            company_prompt = f"""
            Analyze the company at this URL: {company_url}
            
            Provide the following information in this exact format:
            Company: [company name]
            Description: [detailed description of what they do]
            Category: [exactly one of: ConTech Startup, ConTech Investors, or ConTech Adopter]
            
            Be specific and detailed in the description.
            """
            
            response = self.llm.invoke([
                SystemMessage(content="You are a construction technology industry expert."),
                HumanMessage(content=company_prompt)
            ])
            
            # Parse the response
            lines = response.content.strip().split('\n')
            main_company = {}
            for line in lines:
                if ':' in line:
                    key, value = line.split(':', 1)
                    main_company[key.strip()] = value.strip()
            
            return main_company
            
        except Exception as e:
            print(f"\n❌ Error analyzing company: {str(e)}")
            return None

    def search_and_collect_data(self, main_company: Dict, company_url: str) -> Dict[str, List[Dict]]:
        print("\n🔍 Finding related companies...")
        
        try:
            openai_prompt = f"""
            Find {NUM_RELATED_COMPANIES} real companies that could be relevant to:
            Company: {main_company['Company']}
            Category: {main_company['Category']}
            Description: {main_company['Description']}

            Find approximately 3/10 for category 1, 1/10 for category 2, and 6/10 for category 3:
            1) startups, innovators, creators, technology suppliers, early stage companies, 
            2) corporate venture capital, private equity, venture capitalists, investors, 
            3) adopters, 
            in the AEC (Architecture, Engineering, Construction) technology space.
 

            Focus on finding:
            1. Direct competitors
            2. Potential partners or collaborators
            3. Companies in their value chain (suppliers/customers)
            4. Companies with complementary technologies

            
            Use the following urls and to complete this search task.
            - https://www.crunchbase.com/
            - https://contechroundup.substack.com/
            - https://builtworlds.com/
            - https://builtworlds.com/insights/2024-builtworlds-top-50-venture-investors/
            - https://builtworlds.com/insights/2024-top-50-venture-investments-deals/
            - https://builtworlds.com/insights/2025-building-tech-top-50-list/
            - https://builtworlds.com/insights/2024-adoption-leaders-50-list/
            - https://builtworlds.com/insights/2024-global-innovators-list-new/
            - https://builtworlds.com/insights/2025-preconstruction-tech-top-50-list/
            - https://www.constructiondive.com/
            - https://www.constructiondive.com/news/contech-startups-to-watch-2024/632886/
            - https://brickmortar.vc/portfolio 
            - https://techcrunch.com/ 


            For each company, include:
            Company: [name]
            Description: [description]
            Investors: [investors]
            Category: [exactly one of: ConTech Startup, ConTech Investors, or ConTech Adopter]
            URL: [url]
            
            Format each entry exactly as shown above, with each field on a new line.
            """
            
            print(f"Finding {NUM_RELATED_COMPANIES} related companies...")
            
            response = self.llm.invoke([
                SystemMessage(content="You are a construction technology industry expert."),
                HumanMessage(content=openai_prompt)
            ])
            
            results = {"openai": []}
            company_data = self._parse_openai_response(response.content)
            if company_data:
                results["openai"].extend(company_data)
                
            # Add main company to results
            main_company_data = {
                "name": main_company["Company"],
                "description": main_company["Description"],
                "category": main_company["Category"],
                "url": company_url,
                "is_main": True  # Flag to identify the main company
            }
            results["openai"].insert(0, main_company_data)
            
            # Move the PDF generation to after all analysis is complete
            return results
            
        except Exception as e:
            print(f"\n❌ Error finding related companies: {str(e)}")
            return {"openai": []}

    def _parse_openai_response(self, content: str) -> List[Dict]:
        """Helper method to parse OpenAI response into structured data"""
        companies = []
        current_company = {}
        
        lines = content.strip().split('\n')
        for line in lines:
            line = line.strip()
            if not line:
                continue
            
            # If we find a new company entry, save the previous one and start a new one
            if line.lower().startswith("company:"):
                if current_company:  # Save previous company if exists
                    companies.append(current_company)
                current_company = {"is_main": False}  # Initialize new company with is_main flag
            
            # Parse the line
            if ":" in line:
                parts = line.split(":", 1)
                key = parts[0].strip().lower()
                value = parts[1].strip()
                
                if "company" in key:
                    current_company["name"] = value
                elif "description" in key:
                    current_company["description"] = value
                elif "category" in key:
                    current_company["category"] = value
                elif "url" in key:
                    current_company["url"] = value
                elif "investors" in key:
                    current_company["investors"] = value
        
        # Add the last company if exists
        if current_company and "name" in current_company:
            companies.append(current_company)
        
        # Ensure all companies have required fields
        for company in companies:
            company.setdefault("name", "Unknown")
            company.setdefault("description", "N/A")
            company.setdefault("category", "Uncategorized")
            company.setdefault("url", "N/A")
            company.setdefault("is_main", False)
        
        return companies

    def categorize_leads(self, data: Dict[str, List[Dict]]) -> pd.DataFrame:
        categorized_data = []
        BATCH_SIZE = 5  # Process 5 companies at a time
        
        # Flatten the data into a single list
        all_companies = []
        for source, results in data.items():
            for result in results:
                if isinstance(result, str):
                    result = {"name": result, "description": result, "url": "N/A"}
                result["source"] = source
                all_companies.append(result)
        
        total_batches = (len(all_companies) + BATCH_SIZE - 1) // BATCH_SIZE
        
        with tqdm(total=len(all_companies), desc="Categorizing companies") as pbar:
            for i in range(0, len(all_companies), BATCH_SIZE):
                batch = all_companies[i:i + BATCH_SIZE]
                
                # Create batch prompt
                batch_prompt = "Categorize each company into exactly one category: ConTech Startup, ConTech Investors, or ConTech Adopter.\n\n"
                for idx, company in enumerate(batch, 1):
                    clean_name = company.get('name', 'Unknown').replace('*', '').strip()
                    batch_prompt += f"Company {idx}:\nName: {clean_name}\nDescription: {company.get('description', 'N/A')}\n\n"
                
                batch_prompt += "Return ONLY a comma-separated list of categories in order, e.g.: 'ConTech Startup, ConTech Investors, ConTech Adopter'"
                
                response = self.llm.invoke([
                    SystemMessage(content="You are a construction technology expert. Respond only with comma-separated categories."),
                    HumanMessage(content=batch_prompt)
                ])
                
                # Parse categories
                categories = [cat.strip() for cat in response.content.split(',')]
                
                # Add categorized companies to results
                for company, category in zip(batch, categories):
                    clean_name = company.get('name', 'Unknown').replace('*', '').strip()
                    categorized_data.append({
                        "name": clean_name,
                        "category": category,
                        "description": company.get("description", ""),
                        "url": company.get("url", "N/A"),
                        "source": company.get("source", "unknown"),
                        "is_main": company.get("is_main", False)
                    })
                    pbar.update(1)
        
        # Create DataFrame
        df = pd.DataFrame(categorized_data)
        
        # Rename columns to match the expected format
        df = df.rename(columns={
            "name": "Name",
            "category": "Category",
            "description": "Description",
            "url": "URL",
            "source": "Source"
        })
        
        return df[["Name", "Category", "Description", "URL", "Source", "is_main"]]

    def create_stakeholder_map(self, df: pd.DataFrame) -> nx.Graph:
        G = nx.Graph()
        
        # Add nodes
        main_company = df[df['is_main'] == True].iloc[0]
        other_companies = df[df['is_main'] == False]
        
        # Add main company node first
        G.add_node(main_company["Name"], 
                   category=main_company["Category"],
                   is_main=True)
        
        # Add other company nodes
        for _, row in other_companies.iterrows():
            G.add_node(row["Name"], 
                      category=row["Category"],
                      is_main=False)
        
        # Analyze connections with main company first
        print("\n🔍 Analyzing connections with main company...")
        with tqdm(total=len(other_companies), desc="Main company connections") as pbar:
            for _, other_company in other_companies.iterrows():
                connection_prompt = f"""
                Analyze if there's a potential connection between these companies:
                
                Company 1 (Main): {main_company['Name']} ({main_company['Category']})
                Description: {main_company['Description']}
                
                Company 2: {other_company['Name']} ({other_company['Category']})
                Description: {other_company['Description']}
                
                Consider these types of connections:
                1. Direct competition (same market/solutions)
                2. Potential partnership opportunities
                3. Value chain relationship (supplier/customer)
                4. Technology complementarity
                5. Similar target market
                
                Respond with EXACTLY one line containing only 'Yes' or 'No'.
                """
                
                try:
                    response = self.llm.invoke([
                        SystemMessage(content="You are analyzing business connections. Respond only with Yes or No."),
                        HumanMessage(content=connection_prompt)
                    ])
                    
                    # Clean up response and check for connection
                    response_text = response.content.strip().lower()
                    if 'yes' in response_text:
                        G.add_edge(main_company["Name"], other_company["Name"])
                        print(f"\n✅ Connection found: {main_company['Name']} - {other_company['Name']}")
                except Exception as e:
                    print(f"\n❌ Error analyzing connection: {str(e)}")
                
                pbar.update(1)
        
        # Analyze connections between other companies (optional, can be skipped for larger datasets)
        if len(other_companies) < 20:  # Only do this for smaller datasets
            print("\n🔍 Analyzing connections between other companies...")
            total_pairs = (len(other_companies) * (len(other_companies) - 1)) // 2
            with tqdm(total=total_pairs, desc="Other connections") as pbar:
                for i, company1 in other_companies.iterrows():
                    for j, company2 in other_companies.iterrows():
                        if i < j:  # Avoid checking same pair twice
                            connection_prompt = f"""
                            Analyze if there's a potential connection between these companies:
                            
                            Company 1: {company1['Name']} ({company1['Category']})
                            Description: {company1['Description']}
                            
                            Company 2: {company2['Name']} ({company2['Category']})
                            Description: {company2['Description']}
                            
                            Consider these types of connections:
                            1. Direct competition (same market/solutions)
                            2. Potential partnership opportunities
                            3. Value chain relationship (supplier/customer)
                            4. Technology complementarity
                            5. Similar target market
                            
                            Respond with EXACTLY one line containing only 'Yes' or 'No'.
                            """
                            
                            try:
                                response = self.llm.invoke([
                                    SystemMessage(content="You are analyzing business connections. Respond only with Yes or No."),
                                    HumanMessage(content=connection_prompt)
                                ])
                                
                                # Clean up response and check for connection
                                response_text = response.content.strip().lower()
                                if 'yes' in response_text:
                                    G.add_edge(company1["Name"], company2["Name"])
                                    print(f"\n✅ Connection found: {company1['Name']} - {company2['Name']}")
                            except Exception as e:
                                print(f"\n❌ Error analyzing connection: {str(e)}")
                            
                            pbar.update(1)
        
        return G

    def generate_propositions(self, df: pd.DataFrame) -> Dict[str, str]:
        propositions = {}
        relations_data = [] if not SKIP_RELATIONS_CSV else None
        
        # Find the main company
        main_company = df[df['is_main'] == True].iloc[0]
        other_companies = df[df['is_main'] == False]
        
        def process_company(other_company):
            # First analyze potential synergy and connection type
            analysis_prompt = f"""
            Analyze the potential connection between:
            
            Main Company: {main_company['Name']} ({main_company['Category']})
            Description: {main_company['Description']}
            
            Other Company: {other_company['Name']} ({other_company['Category']})
            Description: {other_company['Description']}
            
            Provide your analysis in this exact format:
            Has Synergy: [Yes/No]
            Connection Type: [one of: Direct Competitor, Potential Partner, Value Chain Member, Technology Complementary]
            Synergy Details: [2-3 sentences describing specific ways these companies could work together or compete]
            Value Proposition: [1-2 sentences on mutual benefits]
            """
            
            response = self.llm.invoke([
                SystemMessage(content="You are a construction technology expert analyzing business connections."),
                HumanMessage(content=analysis_prompt)
            ])
            
            # Parse the analysis response
            analysis_lines = response.content.strip().split('\n')
            analysis = {}
            for line in analysis_lines:
                if ':' in line:
                    key, value = line.split(':', 1)
                    analysis[key.strip()] = value.strip()
            
            has_synergy = analysis.get('Has Synergy', '').lower() == 'yes'
            
            company_results = {
                'propositions': None,
                'relations': [] if not SKIP_RELATIONS_CSV else None
            }
            
            if has_synergy:
                if not SKIP_RELATIONS_CSV:
                    company_results['relations'].append({
                        'Company1': main_company['Name'],
                        'Category1': main_company['Category'],
                        'Company2': other_company['Name'],
                        'Category2': other_company['Category'],
                        'Connection_Type': analysis.get('Connection Type', 'Unknown'),
                        'Synergy_Details': analysis.get('Synergy Details', '')
                    })
                
                # Create a more detailed proposition based on the analysis
                proposition_prompt = f"""
                Create a personalized LinkedIn message (max 500 characters) for {other_company['Name']} that includes:
                1. Brief introduction mentioning {main_company['Name']}
                2. Specific reference to: {analysis.get('Connection Type')}
                3. Value proposition: {analysis.get('Value Proposition')}
                4. Concrete suggestion based on: {analysis.get('Synergy Details')}
                5. Clear call to action for a meeting or discussion
                
                Make it professional but conversational.
                """
                
                prop_response = self.llm.invoke([
                    SystemMessage(content="Create personalized, business-focused LinkedIn messages."),
                    HumanMessage(content=proposition_prompt)
                ])
                
                company_results['propositions'] = (
                    other_company["Name"],
                    {
                        'message': prop_response.content,
                        'connection_type': analysis.get('Connection Type', 'Unknown'),
                        'synergy_details': analysis.get('Synergy Details', ''),
                        'value_proposition': analysis.get('Value Proposition', '')
                    }
                )
            
            return company_results
        
        # Process companies in parallel
        with ThreadPoolExecutor(max_workers=3) as executor:
            future_to_company = {
                executor.submit(process_company, row): row['Name']
                for _, row in other_companies.iterrows()
            }
            
            with tqdm(total=len(other_companies), desc="Generating propositions") as pbar:
                for future in as_completed(future_to_company):
                    company_name = future_to_company[future]
                    try:
                        result = future.result()
                        if result['propositions']:
                            propositions[result['propositions'][0]] = result['propositions'][1]
                        if not SKIP_RELATIONS_CSV and result['relations']:
                            relations_data.extend(result['relations'])
                    except Exception as e:
                        print(f"\nError processing {company_name}: {str(e)}")
                    pbar.update(1)
        
        # Save relations to CSV with more details
        if not SKIP_RELATIONS_CSV and relations_data:
            relations_df = pd.DataFrame(relations_data)
            output_path = os.path.join(self.output_dir, 'company_relations.csv')
            relations_df.to_csv(output_path, index=False)
        
        # Save detailed propositions
        output_path = os.path.join(self.output_dir, 'propositions.txt')
        with open(output_path, 'w') as f:
            for name, prop_data in propositions.items():
                f.write(f"\n{'='*50}\n")
                f.write(f"Proposition for: {name}\n")
                f.write(f"{'='*50}\n")
                f.write(f"Connection Type: {prop_data['connection_type']}\n\n")
                f.write(f"Synergy Details:\n{prop_data['synergy_details']}\n\n")
                f.write(f"Value Proposition:\n{prop_data['value_proposition']}\n\n")
                f.write(f"Proposed LinkedIn Message:\n{prop_data['message']}\n\n")
        
        return propositions

    def visualize_stakeholder_map(self, G: nx.Graph):
        plt.figure(figsize=(15, 10))  # Increased figure size
        
        # Use a more spread out layout
        pos = nx.spring_layout(G, k=1, iterations=50)  # k=1 increases spacing between nodes
        
        # Draw nodes for each category with different colors
        colors = {
            "ConTech Startup": "skyblue",
            "ConTech Investors": "lightgreen",
            "ConTech Adopter": "salmon",
        }
        
        # Draw regular nodes first
        for category, color in colors.items():
            nodes = [node for node, attr in G.nodes(data=True) 
                    if attr.get("category") == category and not attr.get("is_main", False)]
            nx.draw_networkx_nodes(G, pos, nodelist=nodes, node_color=color, 
                                 node_size=1000, alpha=0.7)
        
        # Draw main company node with special formatting
        main_nodes = [node for node, attr in G.nodes(data=True) if attr.get("is_main", True)]
        if main_nodes:
            nx.draw_networkx_nodes(G, pos, nodelist=main_nodes, 
                                 node_color='gold',  # Different color for main company
                                 node_size=2000,     # Larger size
                                 alpha=1.0,          # Full opacity
                                 edgecolors='red',   # Red border
                                 linewidths=2)       # Thicker border
        
        # Draw edges with better visibility
        nx.draw_networkx_edges(G, pos, 
                              edge_color='gray',
                              width=2,
                              alpha=0.6,
                              style='solid')
        
        # Add labels with better formatting
        labels = nx.get_node_attributes(G, 'name')
        nx.draw_networkx_labels(G, pos, 
                              font_size=8,
                              font_weight='bold')
        
        # Add legend with main company
        legend_elements = [
            plt.Line2D([0], [0], marker='o', color='w', 
                       markerfacecolor=color, label=cat, markersize=10)
            for cat, color in colors.items()
        ]
        legend_elements.append(
            plt.Line2D([0], [0], marker='o', color='w',
                       markerfacecolor='gold', label='Main Company',
                       markersize=12, markeredgecolor='red', markeredgewidth=2)
        )
        plt.legend(handles=legend_elements, loc='upper left', bbox_to_anchor=(1, 1))
        
        plt.title("AEC Technology Stakeholder Network", pad=20)
        plt.axis('off')
        plt.tight_layout()
        
        # Save to script directory
        output_path = os.path.join(self.output_dir, 'stakeholder_map.png')
        plt.savefig(output_path, bbox_inches='tight', dpi=300)  # Higher resolution
        plt.close()

    def save_initial_search_pdf(self, main_company: Dict, related_companies: List[Dict], G: nx.Graph = None, propositions: Dict = None):
        """Save comprehensive summary report to PDF"""
        from datetime import datetime
        today = datetime.now().strftime("%Y%m%d")
        company_name = "".join(c for c in main_company['Company'] if c.isalnum())
        filename = f"{today}_AEC_Summary_Report_{company_name}.pdf"
        
        # Create PDF
        pdf = FPDF()
        pdf.set_auto_page_break(auto=True, margin=15)
        
        # Function to safely handle text
        def safe_text(text):
            if isinstance(text, str):
                # Replace problematic characters and encode
                return text.encode('latin-1', 'replace').decode('latin-1')
            return str(text)
        
        try:
            pdf.add_page()
            
            # Title Page
            pdf.set_font("Arial", "B", 20)
            pdf.cell(0, 20, "AEC Technology Network Analysis", ln=True, align='C')
            pdf.set_font("Arial", "", 12)
            pdf.cell(0, 10, f"Report Date: {datetime.now().strftime('%Y-%m-%d')}", ln=True, align='C')
            pdf.cell(0, 10, f"Analysis for: {safe_text(main_company['Company'])}", ln=True, align='C')
            pdf.ln(20)
            
            # Table of Contents
            pdf.set_font("Arial", "B", 16)
            pdf.cell(0, 10, "Table of Contents", ln=True)
            pdf.set_font("Arial", "", 12)
            pdf.cell(0, 10, "1. Main Company Profile", ln=True)
            pdf.cell(0, 10, "2. Network Overview", ln=True)
            pdf.cell(0, 10, "3. Related Companies", ln=True)
            pdf.cell(0, 10, "4. Connections Analysis", ln=True)
            pdf.cell(0, 10, "5. Potential Opportunities", ln=True)
            
            # 1. Main Company Profile
            pdf.add_page()
            pdf.set_font("Arial", "B", 16)
            pdf.cell(0, 10, "1. Main Company Profile", ln=True)
            pdf.ln(5)
            
            pdf.set_font("Arial", "B", 12)
            pdf.cell(0, 10, safe_text(f"Company: {main_company['Company']}"), ln=True)
            pdf.cell(0, 10, safe_text(f"Category: {main_company['Category']}"), ln=True)
            pdf.set_font("Arial", "", 12)
            pdf.multi_cell(0, 10, safe_text(f"Description: {main_company['Description']}"))
            pdf.ln(10)
            
            # 2. Network Overview
            pdf.add_page()
            pdf.set_font("Arial", "B", 16)
            pdf.cell(0, 10, "2. Network Overview", ln=True)
            pdf.ln(5)
            
            # Summary statistics
            pdf.set_font("Arial", "", 12)
            total_companies = len(related_companies) + 1
            categories_count = {}
            for company in related_companies:
                cat = company.get('category', 'Uncategorized')
                categories_count[cat] = categories_count.get(cat, 0) + 1
            
            pdf.multi_cell(0, 10, f"Total companies in network: {total_companies}")
            pdf.multi_cell(0, 10, "Distribution by category:")
            for cat, count in categories_count.items():
                pdf.multi_cell(0, 10, safe_text(f"- {cat}: {count} companies"))
            
            # 3. Related Companies
            pdf.add_page()
            pdf.set_font("Arial", "B", 16)
            pdf.cell(0, 10, "3. Related Companies", ln=True)
            pdf.ln(5)
            
            # Group companies by category
            companies_by_category = {}
            for company in related_companies:
                cat = company.get('category', 'Uncategorized')
                if cat not in companies_by_category:
                    companies_by_category[cat] = []
                companies_by_category[cat].append(company)
            
            for category, companies in companies_by_category.items():
                pdf.set_font("Arial", "B", 14)
                pdf.cell(0, 10, safe_text(category), ln=True)
                pdf.ln(5)
                
                for company in companies:
                    pdf.set_font("Arial", "B", 12)
                    pdf.cell(0, 10, safe_text(f"Company: {company['name']}"), ln=True)
                    pdf.set_font("Arial", "", 12)
                    pdf.multi_cell(0, 10, safe_text(f"Description: {company.get('description', 'N/A')}"))
                    if company.get('investors'):
                        pdf.multi_cell(0, 10, safe_text(f"Investors: {company.get('investors', 'N/A')}"))
                    pdf.cell(0, 10, safe_text(f"URL: {company.get('url', 'N/A')}"), ln=True)
                    pdf.ln(5)
            
            # 4. Connections Analysis
            pdf.add_page()
            pdf.set_font("Arial", "B", 16)
            pdf.cell(0, 10, "4. Connections Analysis", ln=True)
            pdf.ln(5)
            
            if G:
                pdf.set_font("Arial", "", 12)
                main_connections = [n for n in G.neighbors(main_company['Company'])]
                
                # Overview section
                pdf.set_font("Arial", "B", 14)
                pdf.cell(0, 10, "Connection Overview", ln=True)
                pdf.set_font("Arial", "", 12)
                pdf.multi_cell(0, 10, safe_text(f"Total direct connections with {main_company['Company']}: {len(main_connections)}"))
                pdf.multi_cell(0, 10, f"Total connections in network: {G.number_of_edges()}")
                pdf.multi_cell(0, 10, f"Network density: {nx.density(G):.2f}")
                pdf.ln(10)
                
                # Detailed connections section
                if main_connections:
                    pdf.set_font("Arial", "B", 14)
                    pdf.cell(0, 10, "Direct Connections Detail", ln=True)
                    pdf.ln(5)
                    
                    for connection in main_connections:
                        # Get connected company details
                        connected_company = next(
                            (c for c in related_companies if c['name'] == connection),
                            None
                        )
                        
                        if connected_company:
                            # Connection header
                            pdf.set_font("Arial", "B", 12)
                            pdf.cell(0, 10, safe_text(f"Connection: {connection}"), ln=True)
                            
                            # Connection details
                            pdf.set_font("Arial", "", 12)
                            pdf.multi_cell(0, 10, safe_text(f"Category: {connected_company.get('category', 'N/A')}"))
                            pdf.multi_cell(0, 10, safe_text(f"Description: {connected_company.get('description', 'N/A')}"))
                            
                            # Add proposition details if available
                            if propositions and connection in propositions:
                                prop = propositions[connection]
                                pdf.multi_cell(0, 10, safe_text(f"Connection Type: {prop.get('connection_type', 'N/A')}"))
                                pdf.multi_cell(0, 10, safe_text(f"Synergy: {prop.get('synergy_details', 'N/A')}"))
                            
                            pdf.cell(0, 10, safe_text(f"URL: {connected_company.get('url', 'N/A')}"), ln=True)
                            pdf.ln(5)
                else:
                    pdf.set_font("Arial", "I", 12)
                    pdf.multi_cell(0, 10, "No direct connections found with the main company.")
                
                pdf.ln(10)
            
            # 5. Potential Opportunities
            pdf.add_page()
            pdf.set_font("Arial", "B", 16)
            pdf.cell(0, 10, "5. Potential Opportunities", ln=True)
            pdf.ln(5)
            
            if propositions:
                for company_name, prop_data in propositions.items():
                    pdf.set_font("Arial", "B", 12)
                    pdf.cell(0, 10, safe_text(f"Opportunity with {company_name}"), ln=True)
                    pdf.set_font("Arial", "", 12)
                    pdf.multi_cell(0, 10, safe_text(f"Connection Type: {prop_data['connection_type']}"))
                    pdf.multi_cell(0, 10, safe_text(f"Synergy Details: {prop_data['synergy_details']}"))
                    pdf.multi_cell(0, 10, safe_text(f"Value Proposition: {prop_data['value_proposition']}"))
                    pdf.ln(5)
            
            # Save the PDF
            output_path = os.path.join(self.output_dir, filename)
            pdf.output(output_path)
            return output_path
            
        except Exception as e:
            print(f"\n❌ Error generating PDF: {str(e)}")
            # Fallback to basic ASCII filename if needed
            fallback_filename = f"{today}_AEC_Summary_Report_Company.pdf"
            output_path = os.path.join(self.output_dir, fallback_filename)
            try:
                pdf.output(output_path)
                return output_path
            except:
                print("❌ Could not save PDF even with fallback filename")
                return None

def main():
    # Print configuration status
    print("\n🔧 Configuration:")
    print(f"{'✅' if USE_OPENAI else '❌'} OpenAI API: {'Enabled' if USE_OPENAI else 'Disabled'}")
    print(f"{'❌' if SKIP_CATEGORIZATION else '✅'} Categorization: {'Skipped' if SKIP_CATEGORIZATION else 'Enabled'}")
    print(f"{'❌' if SKIP_STAKEHOLDER_MAP else '✅'} Stakeholder Map: {'Skipped' if SKIP_STAKEHOLDER_MAP else 'Enabled'}")
    print(f"{'❌' if SKIP_PROPOSITIONS else '✅'} Propositions: {'Skipped' if SKIP_PROPOSITIONS else 'Enabled'}")
    print(f"{'❌' if SKIP_RELATIONS_CSV else '✅'} Relations CSV: {'Skipped' if SKIP_RELATIONS_CSV else 'Enabled'}")
    print()
    
    # Setup API keys and initialize clients
    setup_api_keys()
    clients = initialize_clients()
    
    # Create agent
    agent = AECNetworkAgent(clients)
    
    # Get company URL from user
    company_url = get_company_input()
    
    # Analyze main company
    main_company = agent.analyze_main_company(company_url)
    if not main_company:
        print("Failed to analyze company. Exiting...")
        return
    
    # Find related companies
    print("🔍 Searching for related companies...")
    data = agent.search_and_collect_data(main_company, company_url)
    
    if not SKIP_CATEGORIZATION:
        print("📊 Categorizing companies...")
        categorized_df = agent.categorize_leads(data)
        # Save to script directory
        output_path = os.path.join(agent.output_dir, 'categorized_leads.csv')
        categorized_df.to_csv(output_path, index=False)
    else:
        # Create a basic DataFrame without categorization
        categorized_data = []
        for source, results in data.items():
            for result in results:
                categorized_data.append({
                    "Name": result.get("name", "Unknown"),
                    "Category": result.get("category", "Uncategorized"),
                    "Description": result.get("description", ""),
                    "URL": result.get("url", "N/A"),
                    "Source": source,
                    "is_main": result.get("is_main", False)
                })
        categorized_df = pd.DataFrame(categorized_data)
        output_path = os.path.join(agent.output_dir, 'leads.csv')
        categorized_df.to_csv(output_path, index=False)
    
    if not SKIP_STAKEHOLDER_MAP:
        print("🕸️ Creating stakeholder map...")
        G = agent.create_stakeholder_map(categorized_df)
        agent.visualize_stakeholder_map(G)
    
    if not SKIP_PROPOSITIONS:
        print("📝 Generating propositions...")
        propositions = agent.generate_propositions(categorized_df)
    
    # Generate the comprehensive PDF report at the end
    print("📄 Generating summary report...")
    pdf_path = agent.save_initial_search_pdf(
        main_company,
        data["openai"],
        G if not SKIP_STAKEHOLDER_MAP else None,
        propositions if not SKIP_PROPOSITIONS else None
    )
    print(f"📄 Summary report saved to: {pdf_path}")
    
    print(f"\n✅ Process complete! Check output files in: {agent.output_dir}")

if __name__ == "__main__":
    main()
